{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marjuk-5540/personal-ai/blob/main/fooocus_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "b9960f08-cb8d-49fa-8b8e-325c3cfe8823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/5.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m5.0/5.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.18.0\n",
            "    Uninstalling pygit2-1.18.0:\n",
            "      Successfully uninstalled pygit2-1.18.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Total 6725 (delta 0), reused 0 (delta 0), pack-reused 6725 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.33 MiB | 22.72 MiB/s, done.\n",
            "Resolving deltas: 100% (3854/3854), done.\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 8.95MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 7.45MB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 94.9MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:01<00:00, 342MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:48<00:00, 147MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 262MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://3c3416fb81554db73e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.65 seconds\n",
            "2025-06-29 02:57:36.743633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751165856.783173    1893 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751165856.792559    1893 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-29 02:57:36.821480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 838\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://3c3416fb81554db73e.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4839654867922650119\n",
            "[Parameters] CFG = 1.62\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A group of young climate activists planting trees on World Environment Day 2025 in a lush green park, with banners reading 'Restore Our Earth'. The background shows clear blue skies, a few drones capturing the event, and diverse people of different ethnicities smiling and participating in eco-friendly activities. Cinematic lighting, ultra-realistic style, epic, stunning, professional composition\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A group of young climate activists planting trees on World Environment Day 2025 in a lush green park, with banners reading 'Restore Our Earth'. The background shows clear blue skies, a few drones capturing the event, and diverse people of different ethnicities smiling and participating in eco-friendly activities. Cinematic lighting, ultra-realistic style, professional color, highly detailed, very\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.29 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.36 seconds\n",
            "100% 60/60 [01:03<00:00,  1.05s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 68.53 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.62 seconds\n",
            "100% 60/60 [01:00<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.26 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 64.46 seconds\n",
            "[Fooocus] Processing enhance ...\n",
            "Enhancement image time: 0.00 seconds\n",
            "Enhancement image time: 0.00 seconds\n",
            "Processing time (total): 132.99 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.83 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 4839654867922650119\n",
            "[Parameters] CFG = 1.62\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "Total time: 0.47 seconds\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 0.59 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.19 seconds\n",
            "100% 60/60 [00:58<00:00,  1.03it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 62.22 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "100% 60/60 [00:55<00:00,  1.09it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 58.85 seconds\n",
            "[Fooocus] Processing enhance ...\n",
            "Enhancement image time: 0.00 seconds\n",
            "Enhancement image time: 0.00 seconds\n",
            "Processing time (total): 121.07 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6289726043308291339\n",
            "[Parameters] CFG = 1.62\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] A dark, dystopian arena inspired by Squid Game Season 3, with masked guards in red uniforms standing in formation. In the center, new contestants in teal tracksuits looking tense and confused, surrounded by surreal, Escher-like staircases and giant LED screens showing the number ‘3’. Neon lighting, intense cinematic shadows, dramatic atmosphere, ultra-realistic style, very detailed, structured, intricate, extremely light, magical, stunning, glowing, rich deep colors color, beautiful perfect, vibrant, epic, coherent, great composition, dynamic, ambient, artistic, pure, positive spiritual, elegant, luxury, elite, calm, cute, magnificent, illuminated, shining, bright, clear, crisp, polished, trendy, iconic, incredible\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] A dark, dystopian arena inspired by Squid Game Season 3, with masked guards in red uniforms standing in formation. In the center, new contestants in teal tracksuits looking tense and confused, surrounded by surreal, Escher-like staircases and giant LED screens showing the number ‘3’. Neon lighting, intense cinematic shadows, dramatic atmosphere, ultra-realistic style, highly detailed, very intricate, stunning, perfect light, illuminated, sharp focus, color, winning, innocent, sublime, extremely inspirational, cute, beautiful, creative, vibrant, passionate, confident, epic, amazing, colorful, background colors, artistic, full, deep romantic, glowing, attractive, elite, fancy, gorgeous, breathtaking, loving, symmetry, great composition\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.24 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.16 seconds\n",
            "100% 60/60 [00:56<00:00,  1.06it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 60.68 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "100% 60/60 [00:55<00:00,  1.07it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.34 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 59.73 seconds\n",
            "[Fooocus] Processing enhance ...\n",
            "Enhancement image time: 0.00 seconds\n",
            "Enhancement image time: 0.00 seconds\n",
            "Processing time (total): 120.41 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 163.27 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.84 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 8226173184998772243\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] Create a monster, cinematic, intricate, elegant, highly detailed, dramatic light, sharp focus, beautiful, divine, rational, open composition, deep background, symmetry, magic, amazing, great perfect, creative, artistic, thought, very inspirational, stunning, colossal, fantastic, brilliant, loving, fabulous, incredible, spiritual, pure, shiny, wonderful, flowing, bright\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] Create a monster, dramatic, intricate, elegant, highly detailed, dynamic, sharp focus, beautiful, futuristic, thought, perfect, cinematic, background, illuminated, epic, stunning, brave, artistic, vivid colorful, light, color, amazing, symmetry, great composition, professional, awarded, best, atmosphere, creative, positive, unique, awesome, cute, lovely, marvelous\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 2.19 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.16 seconds\n",
            "100% 30/30 [00:29<00:00,  1.00it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 34.15 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.62 seconds\n",
            "100% 30/30 [00:30<00:00,  1.01s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 33.77 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 67.92 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.79 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 6856427978659170851\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] make my image anime style, rember to make same to my face, full transparent flawless, fine detailed, sharp focus, joyful, perfect intricate, innocent, novel, artistic, color rich deep colors, cute, iconic, beautiful, attractive, pure, cool, enhanced, background light, great composition, cinematic, dynamic, atmosphere, new, shiny, amazing, elegant\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] make my image anime style, rember to make same to my face, full color, perfect, detailed, artistic, enhanced, pure, attractive, best, thoughtful, sharp focus, loving, cute, pretty, innocent, light, novel, cheerful, colors, fine detail, inspired, massive, complex background, creative, positive, wonderful, beautiful, dramatic, fantastic\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Fooocus] Image processing ...\n",
            "[Vary] Image is resized because it is too big.\n",
            "[Fooocus] VAE encoding ...\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "Final resolution is (2368, 1728).\n",
            "[Parameters] Denoising Strength = 0.5\n",
            "[Parameters] Initial Latent shape: torch.Size([1, 4, 216, 296])\n",
            "Preparation time: 11.84 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2123857736587524\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            " 30% 9/30 [00:45<01:46,  5.09s/it]\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/websockets/websockets_impl.py\", line 244, in run_asgi\n",
            "    result = await self.app(self.scope, self.asgi_receive, self.asgi_send)  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 152, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/cors.py\", line 77, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 362, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 95, in app\n",
            "    await wrap_app_handling_exceptions(app, session)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 93, in app\n",
            "    await func(session)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 383, in app\n",
            "    await dependant.call(**solved_result.values)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 604, in join_queue\n",
            "    session_info = await asyncio.wait_for(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 489, in wait_for\n",
            "    return fut.result()\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/websockets.py\", line 135, in receive_json\n",
            "    self._raise_on_disconnect(message)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/websockets.py\", line 113, in _raise_on_disconnect\n",
            "    raise WebSocketDisconnect(message[\"code\"], message.get(\"reason\"))\n",
            "starlette.websockets.WebSocketDisconnect: (1006, '')\n",
            "100% 30/30 [02:29<00:00,  4.98s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "Warning: Ran out of memory when regular VAE decoding, retrying with tiled VAE decoding.\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 211.64 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2123857736587524\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.61 seconds\n",
            "100% 30/30 [02:28<00:00,  4.95s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.30 seconds\n",
            "Warning: Ran out of memory when regular VAE decoding, retrying with tiled VAE decoding.\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Generating and saving time: 210.55 seconds\n",
            "[Fooocus] Processing enhance ...\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (2368, 1728).\n",
            "[Fooocus] Preparing enhance prompts ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.87 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] make my image anime style, rember to make same to my face, full transparent flawless, fine detailed, sharp focus, joyful, perfect intricate, innocent, novel, artistic, color rich deep colors, cute, iconic, beautiful, attractive, pure, cool, enhanced, background light, great composition, cinematic, dynamic, atmosphere, new, shiny, amazing, elegant\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2123857736587524\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.17 seconds\n",
            "100% 30/30 [02:28<00:00,  4.97s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.31 seconds\n",
            "Warning: Ran out of memory when regular VAE decoding, retrying with tiled VAE decoding.\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Enhancement image time: 222.66 seconds\n",
            "[Fooocus] VAE encoding ...\n",
            "Final resolution is (2368, 1728).\n",
            "[Fooocus] Preparing enhance prompts ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.86 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] make my image anime style, rember to make same to my face, full transparent flawless, fine detailed, sharp focus, joyful, perfect intricate, innocent, novel, artistic, color rich deep colors, cute, iconic, beautiful, attractive, pure, cool, enhanced, background light, great composition, cinematic, dynamic, atmosphere, new, shiny, amazing, elegant\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 1.2123857736587524\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.19 seconds\n",
            "100% 30/30 [02:28<00:00,  4.95s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.29 seconds\n",
            "Warning: Ran out of memory when regular VAE decoding, retrying with tiled VAE decoding.\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2025-06-29/log.html\n",
            "Enhancement image time: 222.26 seconds\n",
            "Processing time (total): 867.11 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 879.08 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.91 seconds\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2199, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/entry_with_update.py\", line 46, in <module>\n",
            "    from launch import *\n",
            "  File \"/content/Fooocus/launch.py\", line 152, in <module>\n",
            "    from webui import *\n",
            "  File \"/content/Fooocus/webui.py\", line 1120, in <module>\n",
            "    shared.gradio_root.launch(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2115, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2203, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/networking.py\", line 49, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7865 <> https://3c3416fb81554db73e.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}